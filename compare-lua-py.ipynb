{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch.utils.serialization import load_lua\n",
    "\n",
    "from _asm import AdaptiveLogSoftmaxWithLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path    = \"/tmp/AdaptiveSoftMax.t7\"\n",
    "nhid    = 32\n",
    "batch   = 4096\n",
    "cutoff  = [10, 50]\n",
    "targets = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save lua module to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_str = ','.join(str(item) for item in cutoff + [targets])\n",
    "!th save_asm.lua -nhid $nhid -batch $batch -cutoff $cutoff_str -path $path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load lua module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_lua(path, unknown_classes=True)\n",
    "\n",
    "asm_lua  = data['decoder']\n",
    "crit_lua = data['criterion']\n",
    "input    = data['input']\n",
    "target   = data['target']\n",
    "logprob  = data['logprob']\n",
    "\n",
    "grad_input  = asm_lua['gradInput']\n",
    "asm_output  = asm_lua['output']\n",
    "crit_output = crit_lua['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer parameters from lua module to python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asm_py  = AdaptiveLogSoftmaxWithLoss(in_features=nhid, n_classes=targets, cutoffs=cutoff).to(th.double)\n",
    "\n",
    "mapping = {\n",
    "    'head.weight':     asm_lua['head'].weight,\n",
    "    'tail.0.0.weight': asm_lua['tail'][0].get(0).weight,\n",
    "    'tail.0.1.weight': asm_lua['tail'][0].get(1).weight,\n",
    "    'tail.1.0.weight': asm_lua['tail'][1].get(0).weight,\n",
    "    'tail.1.1.weight': asm_lua['tail'][1].get(1).weight,\n",
    "}\n",
    "\n",
    "for name, py_param in asm_py.named_parameters():\n",
    "    lua_param = mapping[name].data\n",
    "    _ = py_param.data.copy_(lua_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the computed loss is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py_loss = 5.901809036515506, lua_loss = 5.901809036515515\n"
     ]
    }
   ],
   "source": [
    "py_loss = asm_py(input, target - 1).loss.item()\n",
    "\n",
    "print(f'py_loss = {py_loss}, lua_loss = {crit_output}')\n",
    "assert abs(py_loss - crit_output) < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the computed logprobs are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lua shape: torch.Size([4096, 100]), Py shape: torch.Size([4096, 100])\n",
      "Sum of absolute differences: 8.469758228102364e-11\n"
     ]
    }
   ],
   "source": [
    "py_logprob = asm_py.log_prob(input)\n",
    "diff = th.sum(th.abs(py_logprob - logprob)).item()\n",
    "\n",
    "print(f'Lua shape: {logprob.shape}, Py shape: {py_logprob.shape}')\n",
    "print(f'Sum of absolute differences: {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the grads wrt weights are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of absolute gradient differences: 6.161169427562011e-17\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    'head.weight':     asm_lua['head'].gradWeight,\n",
    "    'tail.0.0.weight': asm_lua['tail'][0].get(0).gradWeight,\n",
    "    'tail.0.1.weight': asm_lua['tail'][0].get(1).gradWeight,\n",
    "    'tail.1.0.weight': asm_lua['tail'][1].get(0).gradWeight,\n",
    "    'tail.1.1.weight': asm_lua['tail'][1].get(1).gradWeight,\n",
    "}\n",
    "\n",
    "input = input.detach().requires_grad_(True)\n",
    "asm_py(input, target - 1).loss.backward()\n",
    "\n",
    "diff = 0.\n",
    "for name, param in asm_py.named_parameters():\n",
    "    diff += th.sum(th.abs(param.grad.data - mapping[name])).item()\n",
    "    \n",
    "print(f'Sum of absolute gradient differences: {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the grads wrt inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of absolute gradient differences: 2.0263020031955953e-16\n"
     ]
    }
   ],
   "source": [
    "diff = th.sum(th.abs(input.grad - grad_input)).item()\n",
    "\n",
    "print(f'Sum of absolute gradient differences: {diff}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
